Metadata-Version: 2.1
Name: multimath
Version: 1.0
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch==2.1.2
Requires-Dist: torchvision==0.16.2
Requires-Dist: transformers==4.37.2
Requires-Dist: tokenizers==0.15.1
Requires-Dist: sentencepiece==0.1.99
Requires-Dist: shortuuid
Requires-Dist: accelerate==0.21.0
Requires-Dist: peft
Requires-Dist: bitsandbytes
Requires-Dist: pydantic
Requires-Dist: markdown2[all]
Requires-Dist: numpy
Requires-Dist: scikit-learn==1.2.2
Requires-Dist: gradio==4.16.0
Requires-Dist: gradio_client==0.8.1
Requires-Dist: requests
Requires-Dist: httpx==0.23.0
Requires-Dist: uvicorn
Requires-Dist: fastapi
Requires-Dist: einops==0.6.1
Requires-Dist: einops-exts==0.0.4
Requires-Dist: timm==0.6.13
Requires-Dist: python-Levenshtein
Requires-Dist: Levenshtein
Requires-Dist: opencv-python
Requires-Dist: word2number
Requires-Dist: fire
Requires-Dist: latex2sympy2
Requires-Dist: datasets
Requires-Dist: openai==1.3.5
Requires-Dist: ray[default]==2.12.0
Requires-Dist: loralib
Provides-Extra: train
Requires-Dist: deepspeed==0.12.6; extra == "train"
Requires-Dist: ninja; extra == "train"
Requires-Dist: wandb; extra == "train"
Provides-Extra: build
Requires-Dist: build; extra == "build"
Requires-Dist: twine; extra == "build"

#  MultiMath

*Bridging Visual and Mathematical Reasoning for Large Language Models.*


## Contents
- [Install](#install)
- [Data](#data)
- [Train](#train)
- [Evaluation](#evaluation)

## Install


```Shell
pip install --upgrade pip  # enable PEP 660 support
pip install -e .
pip install -e ".[train]"
pip install flash-attn --no-build-isolation
```

## Data

Download datasets to folder `./playground`.
Dataset we used for train including `LLaVA_Pretrain, LLaVA_Instruct, MultiMath, Geo170K, MathV360K`
Please refer to `llava/config/dataset_config.py`
Dataset we used for evaluation including `MathVista, MathVerse, GSM8K, MATH, CMATH, Gaokao-MathCloze`

## Train

run stage 1 training with 
```Shell
bash scripts/pretrain.sh
```

run stage 2 training with 
```Shell
bash scripts/finetune.sh
```

run stage 3 training with 
```Shell
bash scripts/math_finetune.sh
```

## Evaluation

Download the model weight to `./checkpoints/multimath-7b-llavav1_5`
Eval on MathVista:
Run the shell files in `eval_mathvista/scripts`
Eval on MathVerse:
Run the shell files in `eval_mathvista/scripts`
Eval on GSM8K, MATH, CMATH and Gaokao-MathCloze:
Run the shell files in `eval_text/scripts`


## Acknowledgement

- [LLaVA](https://github.com/haotian-liu/LLaVA)
- [DeepSeekMath](https://github.com/deepseek-ai/DeepSeek-Math)
- [Math-LLaVA](https://github.com/HZQ950419/Math-LLaVA)
- [MathVista](https://github.com/lupantech/MathVista)
- [MathVerse](https://github.com/ZrrSkywalker/MathVerse)
